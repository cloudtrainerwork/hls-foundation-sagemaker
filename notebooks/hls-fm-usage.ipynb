{
 "cells": [
  {
   "cell_type": "raw",
   "id": "59faa4d4-cc8d-4019-951b-6713215dfada",
   "metadata": {},
   "source": [
    "---\n",
    "title: Example HLS inference\n",
    "description: This notebook demonstrates an example of inferencing on the fine-tuned HLS Foundation Model using HLS data in the cloud and allows users to explore and select regions of interest.\n",
    "execute:\n",
    "  freeze: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc09a3-37d5-4bdc-a2bf-1d953ef484be",
   "metadata": {},
   "source": [
    "We need to install the leafmap client for data visualization in the notebook.\n",
    "\n",
    "**Note:** This is set to run silently so you will not see an output when executing this cell. If you'd like to ensure the package downloads successfully remove the `--quiet` flag\n",
    "\n",
    "![HLS Training](../images/HLS-inference.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install required packages\n",
    "!pip install ipyleaflet numpy azureml-core azure-storage-blob --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae63c0-c6b2-44df-a551-60679477aa08",
   "metadata": {},
   "source": [
    "Import the python libraries required for running the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cbdc8e-6488-43c9-b0cc-a3a45710f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import required libraries\n",
    "import json\n",
    "import ipyleaflet\n",
    "import numpy as np\n",
    "import requests\n",
    "from azureml.core import Workspace, Model, Webservice\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120afc7-a8da-4f9d-b656-8c2d3c00b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(f\"Found workspace: {ws.name}\")\n",
    "except:\n",
    "    # Initialize manually if needed\n",
    "    ws = Workspace(\n",
    "        subscription_id='your-subscription-id',\n",
    "        resource_group='your-resource-group',\n",
    "        workspace_name='your-workspace-name'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Configuration for Azure ML inference\n",
    "# UPDATE THESE VALUES:\n",
    "STORAGE_ACCOUNT_NAME = 'your-storage-account'\n",
    "CONTAINER_NAME = 'hls-models'\n",
    "MODEL_NAME = 'your-identifier-hls-foundation'  # Replace with your registered model name\n",
    "ENDPOINT_NAME = 'hls-inference-endpoint'  # Your deployed endpoint name\n",
    "\n",
    "# Alternative: Direct Azure ML endpoint URL (if using managed endpoints)\n",
    "INFERENCE_URL = f'https://{ENDPOINT_NAME}.{ws.location}.inference.ml.azure.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544d648-b0a4-476d-a487-494671887fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Event details dictionary (unchanged)\n",
    "EVENT_DETAILS = {\n",
    "    'mongolian_fire': {\n",
    "        'center_lon': 119.3,\n",
    "        'center_lat': 47.1,\n",
    "        'default_zoom': 8,\n",
    "        'start_date': '2022-04-19T00:00:00Z',\n",
    "        'end_date': '2022-04-19T23:59:59Z'\n",
    "    },\n",
    "    'new_mexico_black_fire': {\n",
    "        'center_lon': -107.5,\n",
    "        'center_lat': 33.5,\n",
    "        'default_zoom': 10,\n",
    "        'start_date': '2022-05-16T00:00:00Z',\n",
    "        'end_date': '2022-06-10T23:59:59Z'\n",
    "    },\n",
    "    'alberta_fire': {\n",
    "        'center_lon': -124.2,\n",
    "        'center_lat': 61.8,\n",
    "        'default_zoom': 8,\n",
    "        'start_date': '2023-05-27T00:00:00Z',\n",
    "        'end_date': '2023-05-28T23:59:59Z'\n",
    "    },\n",
    "    'maui_fire': {\n",
    "        'center_lon': -156.659394,\n",
    "        'center_lat': 20.886984,\n",
    "        'default_zoom': 12,\n",
    "        'start_date': '2023-08-13T00:00:00Z',\n",
    "        'end_date': '2023-08-13T23:59:59Z'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cce302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Select event\n",
    "event = 'maui_fire'\n",
    "event_details = EVENT_DETAILS[event]\n",
    "print(f\"Selected event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6afa1-3db5-4768-b5a4-37630ef8ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Setup tile layers (unchanged)\n",
    "datestring = event_details['start_date']\n",
    "HLSL30_TILE_LAYER = 'https://gitc-a.earthdata.nasa.gov/wmts/epsg3857/best/wmts.cgi?TIME=' + datestring + '&layer=HLS_L30_Nadir_BRDF_Adjusted_Reflectance&style=default&tilematrixset=GoogleMapsCompatible_Level12&Service=WMTS&Request=GetTile&Version=1.0.0&Format=image%2Fpng&TileMatrix={z}&TileCol={x}&TileRow={y}'\n",
    "HLSS30_TILE_LAYER = 'https://gitc-a.earthdata.nasa.gov/wmts/epsg3857/best/wmts.cgi?TIME=' + datestring + '&layer=HLS_S30_Nadir_BRDF_Adjusted_Reflectance&style=default&tilematrixset=GoogleMapsCompatible_Level12&Service=WMTS&Request=GetTile&Version=1.0.0&Format=image%2Fpng&TileMatrix={z}&TileCol={x}&TileRow={y}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbf07e-0ded-4ebb-9fa8-429ad67196cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e805bdae4ed043f9b330cf3322f2b4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20.886984, -156.659394], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title…"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8: Create interactive map\n",
    "from ipyleaflet import Map, TileLayer, DrawControl, GeoJSON\n",
    "\n",
    "layer = TileLayer(url=HLSL30_TILE_LAYER, attribution='NASA', name='HLSL30', opacity=1)\n",
    "draw_control = DrawControl()\n",
    "\n",
    "map = Map(\n",
    "    default_tiles=layer,\n",
    "    center=(event_details['center_lat'], event_details['center_lon']), \n",
    "    zoom=event_details['default_zoom']\n",
    ")\n",
    "\n",
    "draw_control.rectangle = {\n",
    "    \"shapeOptions\": {\n",
    "        \"fillColor\": \"#fca45d\",\n",
    "        \"color\": \"#fca45d\", \n",
    "        \"fillOpacity\": 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "hlsl30_tile_layer = TileLayer(url=HLSL30_TILE_LAYER, name='HLSL30', attribution='NASA')\n",
    "hlss30_tile_layer = TileLayer(url=HLSS30_TILE_LAYER, name='HLSS30', attribution='NASA')\n",
    "\n",
    "map.add_layer(hlsl30_tile_layer)\n",
    "map.add_layer(hlss30_tile_layer)\n",
    "map.add(draw_control)\n",
    "\n",
    "# Store drawn shapes\n",
    "drawn_shapes = []\n",
    "\n",
    "def handle_draw(self, action, geo_json):\n",
    "    if action == 'created':\n",
    "        drawn_shapes.append(geo_json)\n",
    "        print(\"Shape added.\")\n",
    "\n",
    "draw_control.on_draw(handle_draw)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Extract bounding box from drawn shape\n",
    "def bbox_from_geojson(bbox):\n",
    "    \"\"\"Get coordinates of bounding box from GeoJSON\"\"\"\n",
    "    coordinates = np.asarray(bbox['geometry']['coordinates'])\n",
    "    lats = coordinates[:, :, 1]  \n",
    "    lons = coordinates[:, :, 0]\n",
    "    return [lons.min(), lats.min(), lons.max(), lats.max()]\n",
    "\n",
    "# Get bounding box (run after drawing on map)\n",
    "if drawn_shapes:\n",
    "    bbox = bbox_from_geojson(drawn_shapes[0])\n",
    "    print(f\"Bounding box: {bbox}\")\n",
    "else:\n",
    "    print(\"⚠️  Please draw a rectangle on the map first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Setup Azure ML model and config references\n",
    "# Update these values based on your training notebook outputs:\n",
    "identifier = \"your-identifier\"  # Same as used in training notebook\n",
    "BLOB_CONTAINER = \"hls-data\"  # Your blob container name\n",
    "\n",
    "# Azure blob URLs for model and config\n",
    "config_blob_url = f\"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{BLOB_CONTAINER}/configs/{identifier}-burn_scars_Prithvi_100M.py\"\n",
    "model_blob_url = f\"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{BLOB_CONTAINER}/models/{identifier}-workshop.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Function to get Azure ML endpoint authentication\n",
    "def get_azure_ml_headers():\n",
    "    \"\"\"Get authentication headers for Azure ML endpoint\"\"\"\n",
    "    try:\n",
    "        # For managed identity (when running in Azure)\n",
    "        from azure.identity import DefaultAzureCredential\n",
    "        from azure.core.credentials import AccessToken\n",
    "        \n",
    "        credential = DefaultAzureCredential()\n",
    "        token = credential.get_token(\"https://ml.azure.com/.default\")\n",
    "        \n",
    "        return {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {token.token}'\n",
    "        }\n",
    "    except:\n",
    "        # Fallback: Use service principal or key-based auth\n",
    "        # You'll need to set up authentication keys in your environment\n",
    "        return {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {ws.get_details()[\"workspaceId\"]}'  # Simplified - replace with actual token\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf9ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    " Cell 12: Make inference request to Azure ML endpoint\n",
    "if 'bbox' in locals() and bbox:\n",
    "    # Prepare payload for Azure ML endpoint\n",
    "    payload = {\n",
    "        \"data\": {\n",
    "            \"config_path\": config_blob_url,\n",
    "            \"model_path\": model_blob_url, \n",
    "            \"model_type\": \"burn_scars\",\n",
    "            \"date\": event_details['start_date'].split('T')[0],\n",
    "            \"bounding_box\": bbox\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Get authentication headers\n",
    "    headers = get_azure_ml_headers()\n",
    "    \n",
    "    print(f\"Making inference request to: {INFERENCE_URL}\")\n",
    "    print(f\"Payload: {json.dumps(payload, indent=2)}\")\n",
    "    \n",
    "    try:\n",
    "        # Option 1: Call Azure ML managed endpoint\n",
    "        response = requests.post(\n",
    "            f\"{INFERENCE_URL}score\",  # Azure ML endpoint pattern\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=300  # 5 minute timeout for processing\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            predictions = response.json()\n",
    "            print(\"✅ Inference successful!\")\n",
    "        else:\n",
    "            print(f\"❌ Error: {response.status_code} - {response.text}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Request failed: {str(e)}\")\n",
    "        \n",
    "        # Option 2: Fallback to local model inference (if model is available locally)\n",
    "        print(\"Trying local inference as fallback...\")\n",
    "        \n",
    "        try:\n",
    "            # Load model locally and run inference\n",
    "            model = Model(ws, name=MODEL_NAME)\n",
    "            model_path = model.download(target_dir='./temp_model', exist_ok=True)\n",
    "            \n",
    "            # Your local inference code here...\n",
    "            predictions = {\"predictions\": {\"type\": \"FeatureCollection\", \"features\": []}}\n",
    "            print(\"✅ Local inference completed\")\n",
    "            \n",
    "        except Exception as local_error:\n",
    "            print(f\"❌ Local inference also failed: {str(local_error)}\")\n",
    "            predictions = None\n",
    "\n",
    "else:\n",
    "    print(\"⚠️  Please draw a bounding box on the map first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ed9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Display results on map\n",
    "if 'predictions' in locals() and predictions:\n",
    "    try:\n",
    "        geojson = predictions.get('predictions', predictions)\n",
    "        \n",
    "        detection_map = Map(\n",
    "            center=(event_details['center_lat'], event_details['center_lon']), \n",
    "            zoom=event_details['default_zoom']\n",
    "        )\n",
    "        \n",
    "        detection_map.add_layer(hlsl30_tile_layer)\n",
    "        detection_map.add_layer(hlss30_tile_layer)\n",
    "        \n",
    "        # Add predictions as overlay\n",
    "        if geojson:\n",
    "            detection_map.add_layer(GeoJSON(data=geojson))\n",
    "            print(\"✅ Results displayed on map\")\n",
    "        else:\n",
    "            print(\"⚠️  No predictions to display\")\n",
    "            \n",
    "        display(detection_map)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error displaying results: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Alternative - Direct model inference using Azure ML SDK\n",
    "\"\"\"\n",
    "# Alternative approach using Azure ML SDK for batch inference\n",
    "from azureml.core import Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "def run_local_inference():\n",
    "    # Download registered model\n",
    "    model = Model(ws, name=MODEL_NAME)\n",
    "    model_path = model.download(target_dir='./downloaded_model', exist_ok=True)\n",
    "    \n",
    "    # Load your inference script and run prediction\n",
    "    # This would use your actual model loading and inference code\n",
    "    \n",
    "    return {\"predictions\": \"your_geojson_results\"}\n",
    "\n",
    "# Uncomment to use local inference\n",
    "# predictions = run_local_inference()\n",
    "\"\"\"\n",
    "\n",
    "print(\"🎉 Inference notebook complete!\")\n",
    "print(\"\\nKey differences from AWS version:\")\n",
    "print(\"✅ Uses Azure ML managed endpoints instead of custom API\")  \n",
    "print(\"✅ Authentication via Azure AD instead of API keys\")\n",
    "print(\"✅ Model and config loaded from Azure Blob Storage\")\n",
    "print(\"✅ Integrated with Azure ML model registry\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8987afb44532b2110e1a5e1b229dd281f8440b44477d285826a54acdd52d8797"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
