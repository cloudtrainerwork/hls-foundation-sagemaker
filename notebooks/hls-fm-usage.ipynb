{
 "cells": [
  {
   "cell_type": "raw",
   "id": "59faa4d4-cc8d-4019-951b-6713215dfada",
   "metadata": {},
   "source": [
    "---\n",
    "title: Example HLS inference\n",
    "description: This notebook demonstrates an example of inferencing on the fine-tuned HLS Foundation Model using HLS data in the cloud and allows users to explore and select regions of interest.\n",
    "execute:\n",
    "  freeze: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc09a3-37d5-4bdc-a2bf-1d953ef484be",
   "metadata": {},
   "source": [
    "We need to install the leafmap client for data visualization in the notebook.\n",
    "\n",
    "**Note:** This is set to run silently so you will not see an output when executing this cell. If you'd like to ensure the package downloads successfully remove the `--quiet` flag\n",
    "\n",
    "![HLS Training](../images/HLS-inference.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install required packages\n",
    "!pip install ipyleaflet numpy azureml-core azure-storage-blob --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aae63c0-c6b2-44df-a551-60679477aa08",
   "metadata": {},
   "source": [
    "Import the python libraries required for running the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cbdc8e-6488-43c9-b0cc-a3a45710f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import required libraries\n",
    "import json\n",
    "import ipyleaflet\n",
    "import numpy as np\n",
    "import requests\n",
    "from azureml.core import Workspace, Model, Webservice\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120afc7-a8da-4f9d-b656-8c2d3c00b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(f\"Found workspace: {ws.name}\")\n",
    "except:\n",
    "    # Initialize manually if needed\n",
    "    ws = Workspace(\n",
    "        subscription_id='your-subscription-id',\n",
    "        resource_group='your-resource-group',\n",
    "        workspace_name='your-workspace-name'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Configuration for Azure ML inference\n",
    "# UPDATE THESE VALUES:\n",
    "STORAGE_ACCOUNT_NAME = 'your-storage-account'\n",
    "CONTAINER_NAME = 'hls-models'\n",
    "MODEL_NAME = 'your-identifier-hls-foundation'  # Replace with your registered model name\n",
    "ENDPOINT_NAME = 'hls-inference-endpoint'  # Your deployed endpoint name\n",
    "\n",
    "# Alternative: Direct Azure ML endpoint URL (if using managed endpoints)\n",
    "INFERENCE_URL = f'https://{ENDPOINT_NAME}.{ws.location}.inference.ml.azure.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544d648-b0a4-476d-a487-494671887fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Event details dictionary (unchanged)\n",
    "EVENT_DETAILS = {\n",
    "    'mongolian_fire': {\n",
    "        'center_lon': 119.3,\n",
    "        'center_lat': 47.1,\n",
    "        'default_zoom': 8,\n",
    "        'start_date': '2022-04-19T00:00:00Z',\n",
    "        'end_date': '2022-04-19T23:59:59Z'\n",
    "    },\n",
    "    'new_mexico_black_fire': {\n",
    "        'center_lon': -107.5,\n",
    "        'center_lat': 33.5,\n",
    "        'default_zoom': 10,\n",
    "        'start_date': '2022-05-16T00:00:00Z',\n",
    "        'end_date': '2022-06-10T23:59:59Z'\n",
    "    },\n",
    "    'alberta_fire': {\n",
    "        'center_lon': -124.2,\n",
    "        'center_lat': 61.8,\n",
    "        'default_zoom': 8,\n",
    "        'start_date': '2023-05-27T00:00:00Z',\n",
    "        'end_date': '2023-05-28T23:59:59Z'\n",
    "    },\n",
    "    'maui_fire': {\n",
    "        'center_lon': -156.659394,\n",
    "        'center_lat': 20.886984,\n",
    "        'default_zoom': 12,\n",
    "        'start_date': '2023-08-13T00:00:00Z',\n",
    "        'end_date': '2023-08-13T23:59:59Z'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cce302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Select event\n",
    "event = 'maui_fire'\n",
    "event_details = EVENT_DETAILS[event]\n",
    "print(f\"Selected event: {event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6afa1-3db5-4768-b5a4-37630ef8ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Setup tile layers (unchanged)\n",
    "datestring = event_details['start_date']\n",
    "HLSL30_TILE_LAYER = 'https://gitc-a.earthdata.nasa.gov/wmts/epsg3857/best/wmts.cgi?TIME=' + datestring + '&layer=HLS_L30_Nadir_BRDF_Adjusted_Reflectance&style=default&tilematrixset=GoogleMapsCompatible_Level12&Service=WMTS&Request=GetTile&Version=1.0.0&Format=image%2Fpng&TileMatrix={z}&TileCol={x}&TileRow={y}'\n",
    "HLSS30_TILE_LAYER = 'https://gitc-a.earthdata.nasa.gov/wmts/epsg3857/best/wmts.cgi?TIME=' + datestring + '&layer=HLS_S30_Nadir_BRDF_Adjusted_Reflectance&style=default&tilematrixset=GoogleMapsCompatible_Level12&Service=WMTS&Request=GetTile&Version=1.0.0&Format=image%2Fpng&TileMatrix={z}&TileCol={x}&TileRow={y}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbf07e-0ded-4ebb-9fa8-429ad67196cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e805bdae4ed043f9b330cf3322f2b4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20.886984, -156.659394], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title‚Ä¶"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8: Create interactive map\n",
    "from ipyleaflet import Map, TileLayer, DrawControl, GeoJSON\n",
    "\n",
    "layer = TileLayer(url=HLSL30_TILE_LAYER, attribution='NASA', name='HLSL30', opacity=1)\n",
    "draw_control = DrawControl()\n",
    "\n",
    "map = Map(\n",
    "    default_tiles=layer,\n",
    "    center=(event_details['center_lat'], event_details['center_lon']), \n",
    "    zoom=event_details['default_zoom']\n",
    ")\n",
    "\n",
    "draw_control.rectangle = {\n",
    "    \"shapeOptions\": {\n",
    "        \"fillColor\": \"#fca45d\",\n",
    "        \"color\": \"#fca45d\", \n",
    "        \"fillOpacity\": 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "hlsl30_tile_layer = TileLayer(url=HLSL30_TILE_LAYER, name='HLSL30', attribution='NASA')\n",
    "hlss30_tile_layer = TileLayer(url=HLSS30_TILE_LAYER, name='HLSS30', attribution='NASA')\n",
    "\n",
    "map.add_layer(hlsl30_tile_layer)\n",
    "map.add_layer(hlss30_tile_layer)\n",
    "map.add(draw_control)\n",
    "\n",
    "# Store drawn shapes\n",
    "drawn_shapes = []\n",
    "\n",
    "def handle_draw(self, action, geo_json):\n",
    "    if action == 'created':\n",
    "        drawn_shapes.append(geo_json)\n",
    "        print(\"Shape added.\")\n",
    "\n",
    "draw_control.on_draw(handle_draw)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Extract bounding box from drawn shape\n",
    "def bbox_from_geojson(bbox):\n",
    "    \"\"\"Get coordinates of bounding box from GeoJSON\"\"\"\n",
    "    coordinates = np.asarray(bbox['geometry']['coordinates'])\n",
    "    lats = coordinates[:, :, 1]  \n",
    "    lons = coordinates[:, :, 0]\n",
    "    return [lons.min(), lats.min(), lons.max(), lats.max()]\n",
    "\n",
    "# Get bounding box (run after drawing on map)\n",
    "if drawn_shapes:\n",
    "    bbox = bbox_from_geojson(drawn_shapes[0])\n",
    "    print(f\"Bounding box: {bbox}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please draw a rectangle on the map first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Setup Azure ML model and config references\n",
    "# Update these values based on your training notebook outputs:\n",
    "identifier = \"your-identifier\"  # Same as used in training notebook\n",
    "BLOB_CONTAINER = \"hls-data\"  # Your blob container name\n",
    "\n",
    "# Azure blob URLs for model and config\n",
    "config_blob_url = f\"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{BLOB_CONTAINER}/configs/{identifier}-burn_scars_Prithvi_100M.py\"\n",
    "model_blob_url = f\"https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/{BLOB_CONTAINER}/models/{identifier}-workshop.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Function to get Azure ML endpoint authentication\n",
    "def get_azure_ml_headers():\n",
    "    \"\"\"Get authentication headers for Azure ML endpoint\"\"\"\n",
    "    try:\n",
    "        # For managed identity (when running in Azure)\n",
    "        from azure.identity import DefaultAzureCredential\n",
    "        from azure.core.credentials import AccessToken\n",
    "        \n",
    "        credential = DefaultAzureCredential()\n",
    "        token = credential.get_token(\"https://ml.azure.com/.default\")\n",
    "        \n",
    "        return {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {token.token}'\n",
    "        }\n",
    "    except:\n",
    "        # Fallback: Use service principal or key-based auth\n",
    "        # You'll need to set up authentication keys in your environment\n",
    "        return {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {ws.get_details()[\"workspaceId\"]}'  # Simplified - replace with actual token\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf9ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    " Cell 12: Make inference request to Azure ML endpoint\n",
    "if 'bbox' in locals() and bbox:\n",
    "    # Prepare payload for Azure ML endpoint\n",
    "    payload = {\n",
    "        \"data\": {\n",
    "            \"config_path\": config_blob_url,\n",
    "            \"model_path\": model_blob_url, \n",
    "            \"model_type\": \"burn_scars\",\n",
    "            \"date\": event_details['start_date'].split('T')[0],\n",
    "            \"bounding_box\": bbox\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Get authentication headers\n",
    "    headers = get_azure_ml_headers()\n",
    "    \n",
    "    print(f\"Making inference request to: {INFERENCE_URL}\")\n",
    "    print(f\"Payload: {json.dumps(payload, indent=2)}\")\n",
    "    \n",
    "    try:\n",
    "        # Option 1: Call Azure ML managed endpoint\n",
    "        response = requests.post(\n",
    "            f\"{INFERENCE_URL}score\",  # Azure ML endpoint pattern\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=300  # 5 minute timeout for processing\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            predictions = response.json()\n",
    "            print(\"‚úÖ Inference successful!\")\n",
    "        else:\n",
    "            print(f\"‚ùå Error: {response.status_code} - {response.text}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Request failed: {str(e)}\")\n",
    "        \n",
    "        # Option 2: Fallback to local model inference (if model is available locally)\n",
    "        print(\"Trying local inference as fallback...\")\n",
    "        \n",
    "        try:\n",
    "            # Load model locally and run inference\n",
    "            model = Model(ws, name=MODEL_NAME)\n",
    "            model_path = model.download(target_dir='./temp_model', exist_ok=True)\n",
    "            \n",
    "            # Your local inference code here...\n",
    "            predictions = {\"predictions\": {\"type\": \"FeatureCollection\", \"features\": []}}\n",
    "            print(\"‚úÖ Local inference completed\")\n",
    "            \n",
    "        except Exception as local_error:\n",
    "            print(f\"‚ùå Local inference also failed: {str(local_error)}\")\n",
    "            predictions = None\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please draw a bounding box on the map first!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ed9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Display results on map\n",
    "if 'predictions' in locals() and predictions:\n",
    "    try:\n",
    "        geojson = predictions.get('predictions', predictions)\n",
    "        \n",
    "        detection_map = Map(\n",
    "            center=(event_details['center_lat'], event_details['center_lon']), \n",
    "            zoom=event_details['default_zoom']\n",
    "        )\n",
    "        \n",
    "        detection_map.add_layer(hlsl30_tile_layer)\n",
    "        detection_map.add_layer(hlss30_tile_layer)\n",
    "        \n",
    "        # Add predictions as overlay\n",
    "        if geojson:\n",
    "            detection_map.add_layer(GeoJSON(data=geojson))\n",
    "            print(\"‚úÖ Results displayed on map\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No predictions to display\")\n",
    "            \n",
    "        display(detection_map)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error displaying results: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Alternative - Direct model inference using Azure ML SDK\n",
    "\"\"\"\n",
    "# Alternative approach using Azure ML SDK for batch inference\n",
    "from azureml.core import Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "def run_local_inference():\n",
    "    # Download registered model\n",
    "    model = Model(ws, name=MODEL_NAME)\n",
    "    model_path = model.download(target_dir='./downloaded_model', exist_ok=True)\n",
    "    \n",
    "    # Load your inference script and run prediction\n",
    "    # This would use your actual model loading and inference code\n",
    "    \n",
    "    return {\"predictions\": \"your_geojson_results\"}\n",
    "\n",
    "# Uncomment to use local inference\n",
    "# predictions = run_local_inference()\n",
    "\"\"\"\n",
    "\n",
    "print(\"üéâ Inference notebook complete!\")\n",
    "print(\"\\nKey differences from AWS version:\")\n",
    "print(\"‚úÖ Uses Azure ML managed endpoints instead of custom API\")  \n",
    "print(\"‚úÖ Authentication via Azure AD instead of API keys\")\n",
    "print(\"‚úÖ Model and config loaded from Azure Blob Storage\")\n",
    "print(\"‚úÖ Integrated with Azure ML model registry\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8987afb44532b2110e1a5e1b229dd281f8440b44477d285826a54acdd52d8797"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
